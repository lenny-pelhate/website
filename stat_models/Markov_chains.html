<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introduction to Markov Chains</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h1 {
            text-align: center;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }
        .formula {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 15px 0;
        }
        .math-formula {
            text-align: center;
            margin: 15px 0;
            font-size: 18px;
        }
        .pros-cons {
            display: flex;
            justify-content: space-between;
            margin: 20px 0;
        }
        .pros, .cons {
            flex-basis: 48%;
            padding: 15px;
            border-radius: 5px;
        }
        .pros {
            background-color: #e6f7e9;
        }
        .cons {
            background-color: #fce8e8;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
        .example-container {
            background-color: #f0f8ff;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
        }
        code {
            font-family: Consolas, Monaco, 'Andale Mono', monospace;
            background-color: #f5f5f5;
            padding: 2px 4px;
            border-radius: 3px;
        }
        #visualization {
            margin: 20px 0;
            padding: 15px;
            background-color: #fff;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        .matrix {
            text-align: center;
            margin: 20px 0;
            font-family: monospace;
            font-size: 18px;
        }
        .highlight {
            background-color: #ffeb3b;
            padding: 0 3px;
        }
    </style>
</head>
<body>
    <h1>Introduction to Markov Chains</h1>
    
    <h2>What are Markov Chains?</h2>
    <p>
        A Markov chain is a stochastic model describing a sequence of possible events in which the probability of 
        each event depends only on the state attained in the previous event. In other words, it's a mathematical 
        system that transitions from one state to another according to certain probabilistic rules.
    </p>
    <p>
        The defining characteristic of a Markov chain is that it possesses the <strong>Markov property</strong>: 
        the future state depends only on the current state and not on the sequence of events that preceded it.
    </p>
    
    <h2>The Markov Property</h2>
    <div class="formula">
        <p>Mathematically, if X<sub>t</sub> is the state at time t, the Markov property can be expressed as:</p>
        <div class="math-formula">
            P(X<sub>t+1</sub> = j | X<sub>0</sub> = i<sub>0</sub>, X<sub>1</sub> = i<sub>1</sub>, ..., X<sub>t</sub> = i) = P(X<sub>t+1</sub> = j | X<sub>t</sub> = i)
        </div>
        <p>
            This means that the probability of transitioning to state j at time t+1 depends only on the current state i at time t, 
            regardless of all the previous states.
        </p>
    </div>
    
    <h2>Transition Matrix</h2>
    <p>
        The transition matrix P is a key component of a Markov chain. It contains the probabilities of moving from one state to another.
        If we have n states, P is an n×n matrix where each element p<sub>ij</sub> represents the probability of moving from state i to state j.
    </p>
    <div class="formula">
        <div class="math-formula">
            P = [p<sub>ij</sub>] where p<sub>ij</sub> = P(X<sub>t+1</sub> = j | X<sub>t</sub> = i)
        </div>
    </div>
    <p>Properties of the transition matrix:</p>
    <ul>
        <li>All elements are non-negative: p<sub>ij</sub> ≥ 0 for all i, j</li>
        <li>The sum of each row equals 1: ∑<sub>j</sub> p<sub>ij</sub> = 1 for all i</li>
    </ul>
    
    <div class="matrix">
        P = 
        ⎡ p<sub>11</sub> p<sub>12</sub> ... p<sub>1n</sub> ⎤<br>
        ⎢ p<sub>21</sub> p<sub>22</sub> ... p<sub>2n</sub> ⎥<br>
        ⎢ ...  ...  ... ... ⎥<br>
        ⎣ p<sub>n1</sub> p<sub>n2</sub> ... p<sub>nn</sub> ⎦
    </div>
    
    <h2>Proof of Key Properties</h2>
    <div class="formula">
        <h3>Multiple Step Transition Probabilities</h3>
        <p>
            Let's denote p<sub>ij</sub><sup>(n)</sup> as the probability of going from state i to state j in exactly n steps.
            We can compute this using the Chapman-Kolmogorov equation:
        </p>
        <div class="math-formula">
            p<sub>ij</sub><sup>(n+m)</sup> = ∑<sub>k</sub> p<sub>ik</sub><sup>(n)</sup> × p<sub>kj</sub><sup>(m)</sup>
        </div>
        <p>
            In matrix form, this means that the n-step transition matrix P<sup>n</sup> is simply the nth power of the 1-step transition matrix P:
        </p>
        <div class="math-formula">
            P<sup>n</sup> = P × P × ... × P (n times)
        </div>
        
        <h3>Stationary Distribution</h3>
        <p>
            For many Markov chains, the probability distribution of states tends to converge to a steady state,
            known as the stationary distribution π. This distribution satisfies:
        </p>
        <div class="math-formula">
            π = π × P
        </div>
        <p>
            This means that once the system reaches the stationary distribution, it remains there.
            Component-wise, this can be written as:
        </p>
        <div class="math-formula">
            π<sub>j</sub> = ∑<sub>i</sub> π<sub>i</sub> × p<sub>ij</sub> for all j
        </div>
        <p>
            Additionally, since π is a probability distribution, we have:
        </p>
        <div class="math-formula">
            ∑<sub>i</sub> π<sub>i</sub> = 1 and π<sub>i</sub> ≥ 0 for all i
        </div>
    </div>
    
    <h2>Use Cases, Benefits, and Drawbacks</h2>
    
    <h3>Common Use Cases</h3>
    <ul>
        <li>Natural language processing (text generation, speech recognition)</li>
        <li>Finance (modeling stock prices, credit risk assessment)</li>
        <li>Biological sequence analysis (DNA, proteins)</li>
        <li>Page ranking algorithms (Google's original PageRank)</li>
        <li>Weather prediction</li>
        <li>Queueing theory</li>
        <li>Game AI</li>
    </ul>
    
    <div class="pros-cons">
        <div class="pros">
            <h3>Benefits</h3>
            <ul>
                <li>Simple mathematical foundation</li>
                <li>Computationally efficient</li>
                <li>Can model sequential and time-dependent processes</li>
                <li>Well-established theoretical properties</li>
                <li>Useful for prediction and simulation</li>
                <li>Can capture complex behaviors with simple rules</li>
            </ul>
        </div>
        
        <div class="cons">
            <h3>Drawbacks</h3>
            <ul>
                <li>Memoryless property can be too restrictive for some applications</li>
                <li>Cannot directly model processes with long-term dependencies</li>
                <li>Assumes stationarity (transition probabilities don't change over time)</li>
                <li>May require large state spaces for complex problems</li>
                <li>Estimating transition probabilities can be challenging with limited data</li>
            </ul>
        </div>
    </div>
    
    <h2>Concrete Example: Weather Prediction</h2>
    <div class="example-container">
        <p>Consider modeling weather patterns as a Markov chain with three states: Sunny (S), Cloudy (C), and Rainy (R).</p>
        
        <h3>Transition Matrix</h3>
        <p>Based on historical data, we determine the following transition probabilities:</p>
        
        <table>
            <tr>
                <th>From\To</th>
                <th>Sunny</th>
                <th>Cloudy</th>
                <th>Rainy</th>
            </tr>
            <tr>
                <td><strong>Sunny</strong></td>
                <td>0.7</td>
                <td>0.2</td>
                <td>0.1</td>
            </tr>
            <tr>
                <td><strong>Cloudy</strong></td>
                <td>0.4</td>
                <td>0.4</td>
                <td>0.2</td>
            </tr>
            <tr>
                <td><strong>Rainy</strong></td>
                <td>0.2</td>
                <td>0.3</td>
                <td>0.5</td>
            </tr>
        </table>
        
        <p>This gives us the transition matrix:</p>
        
        <div class="matrix">
            P = 
            ⎡ 0.7 0.2 0.1 ⎤<br>
            ⎢ 0.4 0.4 0.2 ⎥<br>
            ⎣ 0.2 0.3 0.5 ⎦
        </div>
        
        <h3>Predicting Weather Sequences</h3>
        <p>If today is sunny, what is the probability that the weather two days from now will be rainy?</p>
        <p>We need to find P(X<sub>2</sub> = R | X<sub>0</sub> = S) = p<sub>SR</sub><sup>(2)</sup></p>
        
        <p>Using the Chapman-Kolmogorov equation:</p>
        <p>p<sub>SR</sub><sup>(2)</sup> = p<sub>SS</sub> × p<sub>SR</sub> + p<sub>SC</sub> × p<sub>CR</sub> + p<sub>SR</sub> × p<sub>RR</sub></p>
        <p>= 0.7 × 0.1 + 0.2 × 0.2 + 0.1 × 0.5</p>
        <p>= 0.07 + 0.04 + 0.05 = 0.16</p>
        
        <p>Therefore, there is a 16% chance it will be rainy two days from now if today is sunny.</p>
        
        <h3>Finding the Stationary Distribution</h3>
        <p>
            The stationary distribution π = [π<sub>S</sub>, π<sub>C</sub>, π<sub>R</sub>] satisfies π = π × P and ∑π<sub>i</sub> = 1.
            This gives us the following system of equations:
        </p>
        <p>π<sub>S</sub> = 0.7π<sub>S</sub> + 0.4π<sub>C</sub> + 0.2π<sub>R</sub></p>
        <p>π<sub>C</sub> = 0.2π<sub>S</sub> + 0.4π<sub>C</sub> + 0.3π<sub>R</sub></p>
        <p>π<sub>R</sub> = 0.1π<sub>S</sub> + 0.2π<sub>C</sub> + 0.5π<sub>R</sub></p>
        <p>π<sub>S</sub> + π<sub>C</sub> + π<sub>R</sub> = 1</p>
        
        <p>Solving this system gives us π ≈ [0.45, 0.30, 0.25].</p>
        
        <p>
            This means that in the long run, regardless of the initial weather, it will be sunny about 45% of the time,
            cloudy about 30% of the time, and rainy about 25% of the time.
        </p>
    </div>
    
    <h2>Visualization of Weather Markov Chain</h2>
    <div id="visualization">
        <svg width="700" height="400" viewBox="0 0 700 400">
            <!-- Background -->
            <rect x="0" y="0" width="700" height="400" fill="#f7f9fc" rx="5" ry="5" />
            
            <!-- States -->
            <circle cx="350" cy="100" r="50" fill="#FFEB3B" stroke="#333" stroke-width="2" /> <!-- Sunny -->
            <circle cx="200" cy="250" r="50" fill="#B3E5FC" stroke="#333" stroke-width="2" /> <!-- Cloudy -->
            <circle cx="500" cy="250" r="50" fill="#90CAF9" stroke="#333" stroke-width="2" /> <!-- Rainy -->
            
            <!-- Labels -->
            <text x="350" y="105" text-anchor="middle" font-weight="bold" font-size="18">Sunny</text>
            <text x="200" y="255" text-anchor="middle" font-weight="bold" font-size="18">Cloudy</text>
            <text x="500" y="255" text-anchor="middle" font-weight="bold" font-size="18">Rainy</text>
            
            <!-- Self-loops -->
            <path d="M 385 65 A 30 30 0 1 1 315 65" fill="none" stroke="#333" stroke-width="2" />
            <text x="350" y="40" text-anchor="middle">0.7</text>
            
            <path d="M 235 215 A 30 30 0 1 1 165 215" fill="none" stroke="#333" stroke-width="2" />
            <text x="200" y="185" text-anchor="middle">0.4</text>
            
            <path d="M 535 215 A 30 30 0 1 1 465 215" fill="none" stroke="#333" stroke-width="2" />
            <text x="500" y="185" text-anchor="middle">0.5</text>
            
            <!-- Transitions between states -->
            <!-- Sunny to Cloudy -->
            <path d="M 310 130 L 240 220" fill="none" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)" />
            <text x="260" y="160" text-anchor="middle">0.2</text>
            
            <!-- Sunny to Rainy -->
            <path d="M 390 130 L 460 220" fill="none" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)" />
            <text x="440" y="160" text-anchor="middle">0.1</text>
            
            <!-- Cloudy to Sunny -->
            <path d="M 230 210 L 320 130" fill="none" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)" />
            <text x="260" y="195" text-anchor="middle">0.4</text>
            
            <!-- Cloudy to Rainy -->
            <path d="M 250 250 L 450 250" fill="none" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)" />
            <text x="350" y="240" text-anchor="middle">0.2</text>
            
            <!-- Rainy to Sunny -->
            <path d="M 470 210 L 380 130" fill="none" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)" />
            <text x="440" y="195" text-anchor="middle">0.2</text>
            
            <!-- Rainy to Cloudy -->
            <path d="M 450 250 L 250 250" fill="none" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)" />
            <text x="350" y="270" text-anchor="middle">0.3</text>
            
            <!-- Arrowhead marker -->
            <defs>
                <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="10" refY="3.5" orient="auto">
                    <polygon points="0 0, 10 3.5, 0 7" fill="#333" />
                </marker>
            </defs>
            
            <!-- Stationary distribution -->
            <rect x="250" y="320" width="200" height="60" fill="#E3F2FD" rx="5" ry="5" stroke="#333" />
            <text x="350" y="340" text-anchor="middle" font-weight="bold">Stationary Distribution</text>
            <text x="350" y="365" text-anchor="middle">π = [0.45, 0.30, 0.25]</text>
        </svg>
    </div>
    
    <h2>Classification of Markov Chains</h2>
    <p>Markov chains can be classified based on several properties:</p>
    
    <h3>Based on State Space</h3>
    <ul>
        <li><strong>Finite:</strong> The state space contains a finite number of states</li>
        <li><strong>Countably Infinite:</strong> The state space is countably infinite</li>
        <li><strong>Continuous:</strong> The state space is uncountable (e.g., any real number in an interval)</li>
    </ul>
    
    <h3>Based on Time</h3>
    <ul>
        <li><strong>Discrete-time:</strong> State changes occur at discrete time steps</li>
        <li><strong>Continuous-time:</strong> State changes can occur at any instant in time</li>
    </ul>
    
    <h3>Based on Recurrence</h3>
    <ul>
        <li><strong>Recurrent state:</strong> Starting from state i, the probability of eventually returning to i is 1</li>
        <li><strong>Transient state:</strong> Starting from state i, there's a positive probability of never returning to i</li>
        <li><strong>Absorbing state:</strong> Once entered, it's impossible to leave (p<sub>ii</sub> = 1)</li>
    </ul>
    
    <h3>Based on Periodicity</h3>
    <ul>
        <li><strong>Periodic:</strong> A state i has period d > 1 if any return to state i must occur in multiples of d time steps</li>
        <li><strong>Aperiodic:</strong> A state with period 1</li>
    </ul>
    
    <h3>Based on Ergodicity</h3>
    <ul>
        <li><strong>Ergodic (irreducible):</strong> It's possible to go from any state to any other state</li>
        <li><strong>Reducible:</strong> There exists at least one state that cannot be reached from some other state</li>
    </ul>
    
    <h2>Summary</h2>
    <p>
        Markov chains are powerful mathematical models for analyzing stochastic processes with the Markov property.
        Their fundamental characteristic is that the future depends only on the present, not on the past.
        This "memoryless" property makes them mathematically tractable while still being flexible enough to model
        a wide range of real-world phenomena.
    </p>
    <p>
        Key components include the transition matrix, which defines the probabilities of moving between states,
        and the stationary distribution, which represents the long-term behavior of the system.
        Despite their limitations, particularly with modeling processes that have long-term dependencies,
        Markov chains remain essential tools in fields ranging from natural language processing to finance,
        biology, and weather forecasting.
    </p>
</body>
</html>